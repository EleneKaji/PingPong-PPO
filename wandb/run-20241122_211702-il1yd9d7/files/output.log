Using device: cuda
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5078],
        [0.5078],
        [0.5078],
        [0.5078],
        [0.5078],
        [0.5078],
        [0.5078],
        [0.5078]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068],
        [0.5068]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073],
        [0.5073]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054],
        [0.5054]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059],
        [0.5059]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
tensor([[0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063],
        [0.5063]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SigmoidBackward0>)
Traceback (most recent call last):
  File "C:\Users\Elene2004\Python\Files\PingPong-PPO\PG.py", line 114, in <module>
    observations, rewards, terminateds, truncateds, _ = envs.step(actions)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\vector\sync_vector_env.py", line 222, in step
    ) = self.envs[i].step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\wrappers\common.py", line 393, in step
    return super().step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\core.py", line 322, in step
    return self.env.step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\wrappers\common.py", line 285, in step
    return self.env.step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\ale_py\env.py", line 304, in step
    return self._get_obs(), reward, is_terminal, is_truncated, self._get_info()
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\ale_py\env.py", line 323, in _get_obs
    return self.ale.getScreenRGB()
KeyboardInterrupt
