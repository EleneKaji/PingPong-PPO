Using cuda device
Step: 0 | Reward: -20.625 | Advantage: 8.5423e-06 | Loss: 1.6351e-08 | Prob: 0.50713 | Log Prob: -0.67899 | Grad Norm: 0.0096795 | Time: 28.392 | Total Time: 0.4732
Step: 8 | Reward: -20.25 | Advantage: -0.00013599 | Loss: -2.284e-08 | Prob: 0.51874 | Log Prob: -0.65635 | Grad Norm: 0.0070898 | Time: 73.658 | Total Time: 1.7008
Step: 16 | Reward: -20.75 | Advantage: 0.00023969 | Loss: -5.1482e-08 | Prob: 0.51127 | Log Prob: -0.68419 | Grad Norm: 0.0092021 | Time: 41.238 | Total Time: 2.3881
Traceback (most recent call last):
  File "C:\Users\Elene2004\Python\Files\PingPong-PPO\Policy_Gradient.py", line 113, in <module>
    reward, discounted_reward, loss, prob, log_prob, grad_norm = train_episode()
  File "C:\Users\Elene2004\Python\Files\PingPong-PPO\Policy_Gradient.py", line 76, in train_episode
    probs = agent(e_obs)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Elene2004\Python\Files\PingPong-PPO\Policy_Gradient.py", line 21, in forward
    x = self.relu(self.conv1(x))
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\torch\nn\modules\activation.py", line 104, in forward
    return F.relu(input, inplace=self.inplace)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\torch\nn\functional.py", line 1500, in relu
    result = torch.relu(input)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
