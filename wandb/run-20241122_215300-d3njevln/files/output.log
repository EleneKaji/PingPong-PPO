Using device: cuda
torch.Size([824, 8]) torch.Size([824, 8])
Episode: 1, Reward: [-13. -15. -12. -21. -21. -14. -15. -21.], Loss: 0.00080860, Time: 7352.31ms
torch.Size([825, 8]) torch.Size([825, 8])
Episode: 2, Reward: [-20. -13. -16. -10. -17. -15. -12. -21.], Loss: -0.00172280, Time: 9209.26ms
Traceback (most recent call last):
  File "C:\Users\Elene2004\Python\Files\PingPong-PPO\PG.py", line 115, in <module>
    observations, rewards, terminateds, truncateds, _ = envs.step(actions)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\vector\sync_vector_env.py", line 222, in step
    ) = self.envs[i].step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\wrappers\common.py", line 393, in step
    return super().step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\core.py", line 322, in step
    return self.env.step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\wrappers\common.py", line 285, in step
    return self.env.step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\ale_py\env.py", line 298, in step
    for _ in range(frameskip):
KeyboardInterrupt
