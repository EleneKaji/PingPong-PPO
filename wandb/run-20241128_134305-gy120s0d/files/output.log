Using cuda device
Step: 0 | Reward: -20.25 | Advantage: 5.1456e-05 | Loss: 7.6385e-08 | Prob: 0.50391 | Log Prob: -0.65577 | Grad Norm: 5729.4 | Time: 12.1 | Total Time: 0.20167
Step: 4 | Reward: -19.75 | Advantage: 0.00032433 | Loss: -3.3996e-08 | Prob: 0.53369 | Log Prob: -0.62977 | Grad Norm: 4524.9 | Time: 16.73 | Total Time: 0.4805
Step: 8 | Reward: -20 | Advantage: 0.00025991 | Loss: -1.1651e-07 | Prob: 0.53418 | Log Prob: -0.62702 | Grad Norm: 5691.7 | Time: 16.65 | Total Time: 0.758
Step: 12 | Reward: -20.25 | Advantage: -0.00054277 | Loss: 0 | Prob: 0.52246 | Log Prob: -0.64921 | Grad Norm: 8189.3 | Time: 12.524 | Total Time: 0.96672
Step: 16 | Reward: -20 | Advantage: -0.00010137 | Loss: 3.1982e-08 | Prob: 0.52588 | Log Prob: -0.64268 | Grad Norm: 2491.5 | Time: 14.431 | Total Time: 1.2072
Step: 20 | Reward: -20.5 | Advantage: 0.00014253 | Loss: -7.6754e-08 | Prob: 0.5293 | Log Prob: -0.63713 | Grad Norm: 2521.7 | Time: 14.182 | Total Time: 1.4436
Step: 24 | Reward: -20.5 | Advantage: 0.00050347 | Loss: -1.3756e-07 | Prob: 0.53125 | Log Prob: -0.63344 | Grad Norm: 5848.9 | Time: 16.501 | Total Time: 1.7186
Step: 28 | Reward: -20.75 | Advantage: 0.00054559 | Loss: 9.4475e-08 | Prob: 0.52539 | Log Prob: -0.64361 | Grad Norm: 5324.1 | Time: 17.577 | Total Time: 2.0116
Step: 32 | Reward: -20 | Advantage: -9.6126e-05 | Loss: -3.6645e-08 | Prob: 0.51807 | Log Prob: -0.65765 | Grad Norm: 2714.9 | Time: 23.498 | Total Time: 2.4032
Step: 36 | Reward: -20.75 | Advantage: -9.2274e-05 | Loss: 1.0852e-07 | Prob: 0.50879 | Log Prob: -0.65014 | Grad Norm: 5195.5 | Time: 19.312 | Total Time: 2.7251
Step: 40 | Reward: -20.25 | Advantage: 0.00038798 | Loss: 1.6176e-07 | Prob: 0.49829 | Log Prob: -0.63252 | Grad Norm: 3942.9 | Time: 22.715 | Total Time: 3.1037
Step: 44 | Reward: -20.75 | Advantage: 0.0010011 | Loss: 2.1172e-07 | Prob: 0.4978 | Log Prob: -0.62885 | Grad Norm: 9940.2 | Time: 20.576 | Total Time: 3.4466
Step: 48 | Reward: -20 | Advantage: 2.2325e-05 | Loss: -1.7785e-07 | Prob: 0.49658 | Log Prob: -0.6252 | Grad Norm: 3176.6 | Time: 22.179 | Total Time: 3.8163
Step: 52 | Reward: -20 | Advantage: -0.0011812 | Loss: -6.6487e-09 | Prob: 0.50098 | Log Prob: -0.63252 | Grad Norm: 14586 | Time: 19.492 | Total Time: 4.1411
Step: 56 | Reward: -21 | Advantage: -0.00068193 | Loss: 2.5349e-07 | Prob: 0.50098 | Log Prob: -0.62702 | Grad Norm: 8097.6 | Time: 25.487 | Total Time: 4.5659
Step: 60 | Reward: -20.25 | Advantage: -0.00037054 | Loss: -2.3321e-08 | Prob: 0.49536 | Log Prob: -0.62155 | Grad Norm: 3219.4 | Time: 23.536 | Total Time: 4.9582
Step: 64 | Reward: -21 | Advantage: -0.00074057 | Loss: 4.0645e-07 | Prob: 0.48877 | Log Prob: -0.60175 | Grad Norm: 6625.3 | Time: 17.551 | Total Time: 5.2507
Step: 68 | Reward: -20.25 | Advantage: -0.00029021 | Loss: -7.9969e-08 | Prob: 0.47803 | Log Prob: -0.58496 | Grad Norm: 2715.1 | Time: 24.834 | Total Time: 5.6646
Step: 72 | Reward: -21 | Advantage: -0.00041114 | Loss: 5.8583e-08 | Prob: 0.46948 | Log Prob: -0.57363 | Grad Norm: 2661.9 | Time: 19.719 | Total Time: 5.9933
Step: 76 | Reward: -20.25 | Advantage: 0.00012645 | Loss: -1.6105e-07 | Prob: 0.46118 | Log Prob: -0.55305 | Grad Norm: 3074.9 | Time: 21.103 | Total Time: 6.345
Step: 80 | Reward: -20.25 | Advantage: 0.0003312 | Loss: -1.0298e-07 | Prob: 0.4541 | Log Prob: -0.53955 | Grad Norm: 2614.7 | Time: 22.711 | Total Time: 6.7235
Step: 84 | Reward: -20.75 | Advantage: -0.001834 | Loss: -2.8693e-07 | Prob: 0.4502 | Log Prob: -0.52873 | Grad Norm: 5366 | Time: 21.961 | Total Time: 7.0895
Step: 88 | Reward: -21 | Advantage: -0.00061792 | Loss: -3.1339e-07 | Prob: 0.44116 | Log Prob: -0.51965 | Grad Norm: 3007.4 | Time: 17.459 | Total Time: 7.3805
Step: 92 | Reward: -20.75 | Advantage: -0.0054363 | Loss: 7.9648e-08 | Prob: 0.43408 | Log Prob: -0.50337 | Grad Norm: 12847 | Time: 21.054 | Total Time: 7.7314
Step: 96 | Reward: -20.75 | Advantage: 0.0026842 | Loss: -1.4261e-07 | Prob: 0.42212 | Log Prob: -0.48893 | Grad Norm: 6916.6 | Time: 20.183 | Total Time: 8.0678
Step: 100 | Reward: -20 | Advantage: 0.0069387 | Loss: -7.2248e-09 | Prob: 0.41553 | Log Prob: -0.47942 | Grad Norm: 14760 | Time: 18.229 | Total Time: 8.3716
Step: 104 | Reward: -20.75 | Advantage: 0.0056126 | Loss: 3.2124e-07 | Prob: 0.41382 | Log Prob: -0.47392 | Grad Norm: 11388 | Time: 13.57 | Total Time: 8.5978
Step: 108 | Reward: -20.75 | Advantage: 0.0023282 | Loss: 3.778e-08 | Prob: 0.42163 | Log Prob: -0.47627 | Grad Norm: 5997.6 | Time: 18.556 | Total Time: 8.907
Step: 112 | Reward: -20.75 | Advantage: -3.2441e-05 | Loss: 3.3344e-07 | Prob: 0.42139 | Log Prob: -0.47942 | Grad Norm: 2517.5 | Time: 18.806 | Total Time: 9.2205
Step: 116 | Reward: -20.5 | Advantage: 0.0018487 | Loss: 2.5811e-08 | Prob: 0.42603 | Log Prob: -0.48893 | Grad Norm: 5608 | Time: 17.477 | Total Time: 9.5118
Step: 120 | Reward: -20.25 | Advantage: 0.0020431 | Loss: 1.206e-07 | Prob: 0.4375 | Log Prob: -0.49773 | Grad Norm: 5278.5 | Time: 19.789 | Total Time: 9.8416
Step: 124 | Reward: -20.75 | Advantage: 0.001543 | Loss: 2.3062e-08 | Prob: 0.44092 | Log Prob: -0.51392 | Grad Norm: 4971 | Time: 19.665 | Total Time: 10.169
Step: 128 | Reward: -20.25 | Advantage: 0.00033033 | Loss: 1.5967e-07 | Prob: 0.4563 | Log Prob: -0.53121 | Grad Norm: 3056.3 | Time: 17.672 | Total Time: 10.464
Step: 132 | Reward: -21 | Advantage: -0.00021837 | Loss: 1.7121e-07 | Prob: 0.4707 | Log Prob: -0.55305 | Grad Norm: 2384.2 | Time: 12.97 | Total Time: 10.68
Step: 136 | Reward: -20 | Advantage: 1.9068e-05 | Loss: -1.474e-07 | Prob: 0.47754 | Log Prob: -0.57017 | Grad Norm: 2514.6 | Time: 18.721 | Total Time: 10.992
Step: 140 | Reward: -20.75 | Advantage: -0.0012602 | Loss: 4.6509e-08 | Prob: 0.49023 | Log Prob: -0.58584 | Grad Norm: 7932.3 | Time: 15.494 | Total Time: 11.25
Step: 144 | Reward: -20.75 | Advantage: -0.00072212 | Loss: -1.5119e-07 | Prob: 0.49756 | Log Prob: -0.59997 | Grad Norm: 3160.6 | Time: 14.982 | Total Time: 11.5
Step: 148 | Reward: -20.25 | Advantage: -0.00015839 | Loss: 6.0169e-08 | Prob: 0.50439 | Log Prob: -0.60443 | Grad Norm: 2453 | Time: 18.465 | Total Time: 11.808
Step: 152 | Reward: -19.75 | Advantage: -0.00072454 | Loss: 4.7027e-09 | Prob: 0.50732 | Log Prob: -0.60801 | Grad Norm: 5590.9 | Time: 21.028 | Total Time: 12.158
Step: 156 | Reward: -20 | Advantage: 7.1919e-05 | Loss: 1.2638e-07 | Prob: 0.50586 | Log Prob: -0.6098 | Grad Norm: 3937.2 | Time: 16.702 | Total Time: 12.437
Step: 160 | Reward: -20.25 | Advantage: 0.0005646 | Loss: 1.7779e-07 | Prob: 0.50684 | Log Prob: -0.6125 | Grad Norm: 5846.4 | Time: 16.817 | Total Time: 12.717
Step: 164 | Reward: -21 | Advantage: -0.00034919 | Loss: 2.3264e-07 | Prob: 0.51562 | Log Prob: -0.61521 | Grad Norm: 3854.9 | Time: 16.12 | Total Time: 12.986
Step: 168 | Reward: -20 | Advantage: -0.0010013 | Loss: 1.3026e-07 | Prob: 0.51416 | Log Prob: -0.61702 | Grad Norm: 7532.2 | Time: 16.235 | Total Time: 13.256
Step: 172 | Reward: -20.75 | Advantage: -0.00050792 | Loss: -1.4171e-07 | Prob: 0.51221 | Log Prob: -0.61792 | Grad Norm: 4485.7 | Time: 17.594 | Total Time: 13.549
Step: 176 | Reward: -20.75 | Advantage: -0.00049103 | Loss: 1.3924e-07 | Prob: 0.51025 | Log Prob: -0.6107 | Grad Norm: 2920.8 | Time: 14.515 | Total Time: 13.791
Step: 180 | Reward: -20.25 | Advantage: 0.00057312 | Loss: -2.3475e-08 | Prob: 0.50781 | Log Prob: -0.59819 | Grad Norm: 8072.8 | Time: 15.1 | Total Time: 14.043
Step: 184 | Reward: -21 | Advantage: -0.001354 | Loss: 6.0471e-08 | Prob: 0.5 | Log Prob: -0.59642 | Grad Norm: 6424.3 | Time: 11.385 | Total Time: 14.233
Step: 188 | Reward: -21 | Advantage: -0.0015806 | Loss: -5.3281e-08 | Prob: 0.50195 | Log Prob: -0.59288 | Grad Norm: 7231.9 | Time: 11.478 | Total Time: 14.424
Step: 192 | Reward: -21 | Advantage: -0.0038104 | Loss: 2.6593e-07 | Prob: 0.49609 | Log Prob: -0.57363 | Grad Norm: 15995 | Time: 15.52 | Total Time: 14.683
Step: 196 | Reward: -20.25 | Advantage: 0.0038192 | Loss: 1.0176e-07 | Prob: 0.48145 | Log Prob: -0.55815 | Grad Norm: 15773 | Time: 13.963 | Total Time: 14.915
Traceback (most recent call last):
  File "C:\Users\Elene2004\Python\Files\PingPong-PPO\Policy_Gradient.py", line 117, in <module>
    reward, discounted_reward, loss, prob, log_prob, grad_norm = train_episode()
  File "C:\Users\Elene2004\Python\Files\PingPong-PPO\Policy_Gradient.py", line 63, in train_episode
    obs, reward, terminated, truncated, info = env.step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\wrappers\common.py", line 393, in step
    return super().step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\core.py", line 322, in step
    return self.env.step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\gymnasium\wrappers\common.py", line 285, in step
    return self.env.step(action)
  File "C:\Users\Elene2004\anaconda3\envs\pong_rl\lib\site-packages\ale_py\env.py", line 298, in step
    for _ in range(frameskip):
KeyboardInterrupt
